{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89239636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Data_embedder.ipynb\n",
      "importing Jupyter notebook from sentence_normalizer.ipynb\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import json\n",
    "import fasttext\n",
    "fasttext.FastText.eprint = lambda x: None\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "import Data_embedder\n",
    "import sentence_normalizer\n",
    "\n",
    "obj_text = codecs.open('/Users/aneripatel/Desktop/SEMESTER-6/30_AIML_Aneri/30_AIML_Aneri_Dataset/embedded_data.json', 'r', encoding='utf-8').read()\n",
    "data = json.loads(obj_text)#json.load() takes a file object and returns the json object. \n",
    "#A JSON object contains data in the form of key/value pair\n",
    "\n",
    "ft_model = Data_embedder.load_embedding_model()\n",
    "\n",
    "\n",
    "def normalize(vec):\n",
    "    norm = np.linalg.norm(vec)\n",
    "\n",
    "    return norm\n",
    "\n",
    "\n",
    "def cosine_similarity(A, B):#Cosine similarity measures the similarity between two \n",
    "#vectors of an inner product space.\n",
    "    normA = normalize(A)\n",
    "    normB = normalize(B)\n",
    "    sim = np.dot(A, B) / (normA * normB)\n",
    "    return sim\n",
    "\n",
    "\n",
    "def detect_intent(data, input_vec):\n",
    "    max_sim_score = -1\n",
    "    max_sim_intent = ''\n",
    "    max_score_avg = -1\n",
    "    break_flag = 0\n",
    "\n",
    "    for intent in data['intents']:\n",
    "\n",
    "        scores = []\n",
    "        intent_flag = 0\n",
    "        tie_flag = 0\n",
    "        for pattern in intent['patterns']:\n",
    "\n",
    "            pattern = np.array(pattern)\n",
    "            similarity = cosine_similarity(pattern, input_vec)\n",
    "            similarity = round(similarity, 6)\n",
    "            scores.append(similarity)\n",
    "            # if exact match is found, then no need to check any further\n",
    "            if similarity == 1.000000:\n",
    "                intent_flag = 1\n",
    "                break_flag = 1\n",
    "                # no need to check any more sentences in this intent\n",
    "                break\n",
    "            elif similarity > max_sim_score:\n",
    "                max_sim_score = similarity\n",
    "                intent_flag = 1\n",
    "            # if a sentence in this intent has same similarity as the max and this max is from a previous intent,\n",
    "            # that means there is a tie between this intent and some previous intent\n",
    "            elif similarity == max_sim_score and intent_flag == 0:\n",
    "                tie_flag = 1\n",
    "        '''\n",
    "        If tie occurs check which intent has max top 4 average\n",
    "        top 4 is taken because even without same intent there are often different ways of expressing the same intent,\n",
    "        which are vector-wise less similar to each other.\n",
    "        Taking an average of all of them, reduced the score of those clusters\n",
    "        '''\n",
    "\n",
    "        if tie_flag == 1:\n",
    "            scores.sort()\n",
    "            top = scores[:min(4, len(scores))]\n",
    "            intent_score_avg = np.mean(top)\n",
    "            if intent_score_avg > max_score_avg:\n",
    "                max_score_avg = intent_score_avg\n",
    "                intent_flag = 1\n",
    "\n",
    "        if intent_flag == 1:\n",
    "            max_sim_intent = intent['tag']\n",
    "        # if exact match was found in this intent, then break 'cause we don't have to iterate through anymore intents\n",
    "        if break_flag == 1:\n",
    "            break\n",
    "    if break_flag != 1 and ((tie_flag == 1 and intent_flag == 1 and max_score_avg < 0.06) or (intent_flag == 1 and max_sim_score < 0.6)):\n",
    "        max_sim_intent = \"\"\n",
    "\n",
    "    return max_sim_intent\n",
    "\n",
    "\n",
    "def classify(input):\n",
    "    input = sentence_normalizer.preprocess_main(input)\n",
    "    input_vec = Data_embedder.embed_sentence(input, ft_model)\n",
    "    output_intent = detect_intent(data, input_vec)\n",
    "    return output_intent\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
